{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Part 0: Introduction to Yelp Dataset Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part 0.0: Yelp Academic Dataset\n",
    "\n",
    "This project delves into exploratory analysis and building predictive models using the [Yelp academic dataset](https://www.yelp.com/dataset_challenge/). It is an opportunity for you to explore a machine learning problem in the context of a real-world data set using big data analysis tools. In order to use the dataset and finish this project, you must agree to the dataset's terms of use provided [here](https://www.yelp.com/html/pdf/Dataset_Challenge_Academic_Dataset_Agreement.pdf).\n",
    "\n",
    "We have chosen a subset of the Yelp academic dataset for you to work with. This subsampled data is loaded into RDDs in section (1). The complete dataset is available from Yelp's website [here](https://www.yelp.com/dataset_challenge/dataset). Remember that you are limited by the DataBricks Community Edition's limits on memory and computation. Yelp has provided some example code at their Github repository [here](https://github.com/Yelp/dataset-examples) that might be helpful in getting started. However, these are pure Python code and not Spark code that provide parallelism.\n",
    "\n",
    "By design, the project is open-ended; you are free to decide how you want to approach the problem and what tools you want to employ. We want to see a best-effort solution that utilizes what you learned in class and also potentially trying new things beyond class. Your project will be worth 20% of your final class grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part 0.1: Grading Rubric:\n",
    "\n",
    "** Course staff will use the following rubric when grading your final project reports: **\n",
    "\n",
    "\n",
    "*  *Introduction/Motivation/Problem Definition (10%)*\n",
    "  * Identify, define, and motivate the problem that you are addressing.\n",
    "  * How (precisely) will a machine learning solution address the problem?\n",
    "\n",
    "*  *Data Understanding and Preparation (15%)*\n",
    "  * What preliminary analyses have you performed on the data? What observations have you made? How did those observations help shape your approach?\n",
    "  * Provide the preliminary data analysis results and your observations.\n",
    "  * Specify how the data will be transformed to the format required for machine learning. \n",
    "\n",
    "*  *Methodology (35%)*\n",
    "  * This is where you give a detailed description of your primary contributions. It is especially important that this part be clear and well written so that we can fully understand what you did.\n",
    "  * Specify the type of model(s) built and/or information/knowledge extracted.\n",
    "  * Discuss choices for machine learning algorithm: what are other alternatives, and what are their pros and cons (in the context of the problem and as compared to your proposed solution)?\n",
    "  * Discuss why and how this model should \"solve\" the problem (i.e., improve along some dimension of interest). \n",
    "  * Outline the big data analysis tools and libraries you have used. \n",
    "\n",
    "It is not so important how well your method performs but rather, (a) how thorough and careful your methodology is, and (b) how interesting and clever the approaches you took and the tools you have used are. \n",
    "\n",
    "*  *Evaluation and Results (30%)*\n",
    "  * We are interested in seeing a clear and conclusive set of experiments which successfully evaluate the problem you set out to solve. Make sure to interpret the results and talk about what we can conclude and learn from your approach.\n",
    "  * How do you evaluate your machine learning solution to the specific question(s) you have addressed?\n",
    "  * What do these results tell you about your solution?\n",
    "  * Present and discuss your evaluation results and findings. You may use tables or figures (e.g. ROC plot) to visualize your results.\n",
    "\n",
    "*  *Style and writing (10%)*\n",
    "  * Overall writing, grammar, organization, figures and illustrations.\n",
    " \n",
    "Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ** Part 0.2: Code of Conduct **\n",
    "\n",
    "** Please follow the following guidelines with respect to collaboration: **\n",
    "\n",
    "* You have to use the data we have provided you. You cannot choose your own dataset. By using the dataset, you agree to Yelp's terms of use available [here](https://www.yelp.com/html/pdf/Dataset_Challenge_Academic_Dataset_Agreement.pdf).\n",
    "* You will be given 48 hours to work on the project. Use of late days are not allowed for this submission.\n",
    "* You are free to use the Web, APIs, ML toolkits, etc. in this project to your best benefit. Please credit any online or offline sources (even casual sources like StackOverflow) if you use them in the project.\n",
    "* Project is to be done individually. No collaboration is allowed between students. No discussion is allowed about the project with anyone else except the class instructors. Students who use each other's ideas or code will be heavily penalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### **Part 0.3: Project Suggestions **\n",
    "\n",
    "Before you embark on the project, please plan out your task by breaking it into smaller chunks that incrementally build on top of each other. For example, you may begin with a simpler set of features and then add more complex features to the dataset. Such modular planning will ensure that you will have a working deliverable in case you run out of time tackling more complicated aspects of the project you had planned to complete. Try to have a barebones but working version of the project after 24 hours, and build on it in the next 24 hours leading up to the deadline. Create a backup version of your notebook after finishing a substantial chunk of the work so you can go back to a working version in case of a catastrophe.\n",
    "\n",
    "**Here is a list of potential aspects you can tackle in this final open-ended project:**\n",
    "\n",
    "*  *Exploratory Data Analysis (Perform those that help you get started with your chosen business question, not all of these.)*\n",
    "  * Plot a map showing the locations of various businesses. Helper code to help in the creation of maps using \"mpl_toolkits\" is provided in a later section on exploratory data analysis.\n",
    "  * Plot a map showing the locations of businesses checkins made by Yelp users.\n",
    "  * Plot a histogram of ratings that the businesses get i.e. see how many businesses got ratings of 1-5 each. Is this distribution skewed? Are there ratings that are used rarely as compared to others?\n",
    "  * What are the most popular keywords that reviewers use by city or state?\n",
    "  * What are the most popular keywords that reviewers use for American/Thai/Chinese restaurants by state?\n",
    "  * What are the most popular keywords or adjectives that reviewers use for American/Thai/Chinese restaurants by state?\n",
    "  * What are the most popular keywords or adjectives that reviewers use in 5 star reviews for American/Thai/Chinese restaurants by state?\n",
    "  * What are the most frequent keywords or adjectives that reviewers use in 1 star reviews for American/Thai/Chinese restaurants by state?\n",
    "  * Does the distribution of restaurants with parking space or outdoor seating differ from state to state or city to city?\n",
    "  * Are there temporal trends (daily, weekly, holidays) associated with business checkins?\n",
    "  * Does the number of checkins per restaurant differ across various restaurant categories?\n",
    "  * Is there a correlation between how long a user has been \"yelping\" and the number of reviews he has written?\n",
    "  * Is there a correlation between how many friends/fans a user has and the number of votes his reviews get?\n",
    "  * What are the 5 most common types of restaurants in each city?\n",
    "  * What is the fraction of businesses that accounts for restaurants?\n",
    "  * Do the typical business hours vary by city and by type of business?\n",
    "  * What does the histogram of number of friends/fans of Yelp users look like? Is it long-tailed or does it follow a certain distribution?\n",
    "  * What is the distribution of number of reviews by neighborhood?\n",
    "  * Is there a correlation between the star rating and length of reviews?\n",
    "  * What are the top keywords or adjectives used by the two genders (male and female, sorry for being binary) in their reviews?\n",
    "  * What fraction of Yelp users is male? What fraction is female? What if the fraction of users for whom gender cannot be determined based on the list of male and female names provided in this notebook?\n",
    "  * What is the average number of friends/fans for male and female users?\n",
    "  * What is the average number of reviews written by male and female users?\n",
    "*  *Classification (Any classification task should also include a description of all the features used and which of these features impacted classification performance the most and why.)*\n",
    "  * Classify businesses into various business categories (restaurant, dry cleaner, auto body, etc.).\n",
    "  * Classify businesses by the type of parking they provide (street, garage, valet, etc.).\n",
    "  * Predict the location of a reviewer (east or west coast or mid-country).\n",
    "  * Predict the location of a business (east or west coast or mid-country).\n",
    "  * Predict if a review is funny, cool, or useful (label should be based on the corresponding votes associated with the review, votes therefore may not be used as features).\n",
    "  * Predict which type of restaurant a user reviews most based on the restaurant types reviewed by his friends.\n",
    "  * Given the current categories of a business, predict a new category that it could be labeled as. You will need businesses - each with mutiple categories - to hold out some categories randomly from each business for testing purposes.\n",
    "  * Predict if two users are friends based on the locations of businesses for which they have written reviews and other user characteristics.\n",
    "  * Based on businesses reviewed by a user until a certain timepoint, predict the type of business the user might review next.\n",
    "  * Predict if the ratings for a business are going to increase or decline with time. Are some types of restaurants more inclines to suffer from declining ratings?\n",
    "  * Predict the gender of Yelp user based on businesses they have written reviews for. Examine a few examples of Yelp users where your classifier is incorrect, and provide any insighful suggestions for improving the classifier.\n",
    "  * Predict the gender of Yelp users based on their business reviews. Examine your model to determine if and how the two genders use different words when writing reviews.\n",
    "  * Predict the gender of Yelp users based on the numbers of various types of votes their reviews get and the numbers of various types of compliments they receive. Examine a few examples of Yelp users where your classifier is incorrect, and provide any insighful suggestions for improving the classifier.\n",
    "*  *Regression (Any regression task should also include a description of all the features used and which of these features impacted regression performance the most and why.)*\n",
    "  * Predict the average rating of a business from its reviews and other business characteristics such as location.\n",
    "  * Predict the total number of reviews on a given week for each business.\n",
    "  * Predict the total number of checkins based on business location, type, and other business characteristics present in \"attributes\" such as \"Happy Hour, \"Accepts Credit Cards\", \"Good For Groups\", \"Outdoor Seating\", and \"Price Range\".\n",
    "  * Predict the number of compliments received by a user.\n",
    "  * Predict the number of friends a user has on Yelp based on user characteristics like number of reviews written by him, compliments received, etc.\n",
    "  * Based on reviews written by a user until a certain timepoint, predict the star rating the user will give as part of his next review. Are certain users more likely to give extreme ratings to reviewed businesses than others?\n",
    "  * Predict the number of funny/cool/useful votes sent by a user. Does it depend significantly on how long the user has been \"yelping\" or on gender?\n",
    "  * Predict the number of funny/cool/useful votes received by a review. Does it depend significantly on how long the user has been \"yelping\" or on gender?\n",
    "* *Clustering*\n",
    "  * Cluster business by using their features using a clustering algorithm such as [K-Means](https://spark.apache.org/docs/2.1.0/mllib-clustering.html#k-means). Choose the number of clusters in a data-driven fashion such as by using the elbow heuristic. Analyze clusters and see if they are homogeneous i.e. the business within each cluster look similar and as if they belong within the same group.\n",
    "  * Cluster users based on their characteristics. See if users in the same cluster patronize similar businesses.\n",
    "* *Recommendation Systems*\n",
    "  * Given previous ratings by a Yelp user, recommend other businesses that the user might like. See [Collaborative Filtering on Spark](https://spark.apache.org/docs/2.1.0/mllib-collaborative-filtering.html).\n",
    "  * You may also think of restaurant/business recommendation as a link prediction problem. You can use GraphX for this task.\n",
    "* *Discovering Insights using Unsupervised Algorithms*\n",
    "  * In the Yelp user dataset, you are provided a social network in the form of friends of each Yelp user. You may perform social network analysis using GraphX. This can help you discover the most influential users by eigen-centrality. You may use other measures of network centrality besides eigen-centrality.\n",
    "  * Discover dense clusters of closely connected friends and see if they patronize the same businesses.\n",
    "  * Verify if the dense clusters of closely connected friends are also homogeneous in terms of gender.\n",
    "  * Learn a set of topics by applying topic modeling algorithms such as [LDA](https://spark.apache.org/docs/2.1.0/mllib-clustering.html#latent-dirichlet-allocation-lda) on textual reviews of businesses. Choose the number of topics in a data-driven fashion such as by using a figure that plots perplexity versus number of topics. Explore if the topics are insightful and whether or not they can be used as inputs to some predictive algorithms (see Classification tasks above).\n",
    "  * Perform the above topic modeling precedure on the reviews of male and female reviewers separately to obtain two topic models. Explore if the topics are insightful and/or useful in any predictive tasks.\n",
    "  * Apply PCA to the matrix where rows are businesses and columns are features of the businesses such as parking type, location, etc. Choose the number of components in a data-driven fashion such as by using a scree plot. Explore if the top components are insightful and can be used as inputs to any predictive algorithms (see classification tasks above).\n",
    "  \n",
    "Your task is to choose one of these ML problems, or define your own, on the provided dataset and address the problem of your choice with the big data analysis tools you learned during the course as well as others you explore based on the APIs in Spark. If you create your own question, please be sure to state it clearly at the beginning of section 4 (methodology)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ** Part 0.4: Setup your DataBricks CE Spark Cluster and IPython Notebook **\n",
    "\n",
    "Step I: Visit the web interface of DataBricks Community Edition at https://community.cloud.databricks.com/.\n",
    "\n",
    "Step II: Start a DataBricks Community Edition cluster by selecting \"New Cluster\" from the homepage.\n",
    "\n",
    "Step III: Give your cluster a name and click on \"Create Cluster\". This creates a single node cluster with 6GB memory for your account.\n",
    "\n",
    "Step IV: Go back to homepage, and choose \"Import Notebook.\" Upload the IPython assignment notebook by following the prompts and open the notebook. Rename the notebook from \"project_yelp_dataset.ipynb\" to \"andrewid_project_yelp_dataset.ipynb\" where \"andrewid\" is your actual Andrew ID.\n",
    "\n",
    "Step V: By default, the notebook is not attached to a Spark cluster and will show \"Detached\" as its status at the top of the notebook in the browser. Click on the \"Detached\" status and attach it to your cluster. It should now show the message as \"Attached (cluster name)\"\n",
    "\n",
    "Step VI: You can now import pyspark into the notebook. Also, attaching to the DataBricks Community Edition cluster automatically provides the SparkContext variable \"sc\" to the Python code in your notebook. Use it to create RDDs and write further Spark code.\n",
    "\n",
    "These instructions are detailed with screenshots in slides 10-16 of the setup recitation available at https://www.andrew.cmu.edu/user/amaurya/docs/95869/hadoop-spark-setup-recitation.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ** Part 0.5: Submission Instructions **\n",
    "\n",
    "You will submit both a zipped file on Blackboard and a hardcopy to the TA Abhinav Maurya in HBH 3026. If the TA's office is closed, please slide the hardcopy under the door.\n",
    "\n",
    "Please complete the project, and feel free to add new cells as required. Upon completion, execute all cells in the completed notebook, and make sure all results show up. Export the contents of the notebook by choosing \"File > Export > HTML\" and saving the resulting file as \"andrewid_project_yelp_dataset.html\" Place the two files \"andrewid_project_yelp_dataset.ipynb\" and \"andrewid_project_yelp_dataset.html\" in a folder, zip the folder to a zipped file named \"andrewid_project.zip\" and submit it to Blackboard by the deadline. In addition, print the HTML file and submit the hardcopy to the TA Abhinav Maurya in HBH 3026 by the deadline. If the TA's office is closed, please slide the hardcopy under the door."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ** Part 1: Load the datasets required for the project **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will load four datasets for this project. Please feel free to reasonably subsample the dataset depending on the question you are answering and its complexity. If you choose to subsample any of the four datasets, please explain why you subsampled it and what was the number of datapoints you were left with in the subsampled version. In addition to the four datasets, we will also load two lists which contain names by gender. These lists are helpful in assigning a gender to a Yelp user by their name, since gender is not available in the Yelp dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import pyspark\n",
    "import urllib2\n",
    "import numpy as np\n",
    "\n",
    "# helper function to load a JSON dataset from a publicly accessible url\n",
    "def get_rdd_from_url(url):\n",
    "  response = urllib2.urlopen(url)\n",
    "  str_contents = response.read().strip().split('\\n')\n",
    "  json_contents = [json.loads(x) for x in str_contents]\n",
    "  rdd = sc.parallelize(json_contents)\n",
    "  return rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first dataset we are going to load is information about Yelp businesses. The information of each business will be stored as a Python dictionary within an RDD. The dictionary consists of the following fields:\n",
    "\n",
    "* \"business_id\":\"encrypted business id\"\n",
    "* \"name\":\"business name\"\n",
    "* \"neighborhood\":\"hood name\"\n",
    "* \"address\":\"full address\"\n",
    "* \"city\":\"city\"\n",
    "* \"state\":\"state -- if applicable --\"\n",
    "* \"postal code\":\"postal code\"\n",
    "* \"latitude\":latitude\n",
    "* \"longitude\":longitude\n",
    "* \"stars\":star rating, rounded to half-stars\n",
    "* \"review_count\":number of reviews\n",
    "* \"is_open\":0/1 (closed/open)\n",
    "* \"attributes\":[\"an array of strings: each array element is an attribute\"]\n",
    "* \"categories\":[\"an array of strings of business categories\"]\n",
    "* \"hours\":[\"an array of strings of business hours\"]\n",
    "* \"type\": \"business\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the data about Yelp businesses in an RDD\n",
    "# each RDD element is a Python dictionary parsed from JSON using json.loads()\n",
    "# if your chosen project does not need this data, please comment out the lines below\n",
    "businesses_rdd = get_rdd_from_url('https://www.andrew.cmu.edu/user/amaurya/docs/95869/yelp_academic_dataset_business.json')\n",
    "print businesses_rdd.count()\n",
    "print businesses_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The second dataset we are going to load is information about Yelp users. Each user's information will be stored as a Python dictionary within an RDD. The dictionary consists of the following fields:\n",
    "\n",
    "*  \"user_id\":\"encrypted user id\"\n",
    "*  \"name\":\"first name\"\n",
    "*  \"review_count\":number of reviews\n",
    "*  \"yelping_since\": date formatted like \"2009-12-19\"\n",
    "*  \"friends\":[\"an array of encrypted ids of friends\"]\n",
    "*  \"useful\":\"number of useful votes sent by the user\"\n",
    "*  \"funny\":\"number of funny votes sent by the user\"\n",
    "*  \"cool\":\"number of cool votes sent by the user\"\n",
    "*  \"fans\":\"number of fans the user has\"\n",
    "*  \"elite\":[\"an array of years the user was elite\"]\n",
    "*  \"average_stars\":floating point average like 4.31\n",
    "*  \"compliment_hot\":number of hot compliments received by the user\n",
    "*  \"compliment_more\":number of more compliments received by the user\n",
    "*  \"compliment_profile\": number of profile compliments received by the user\n",
    "*  \"compliment_cute\": number of cute compliments received by the user\n",
    "*  \"compliment_list\": number of list compliments received by the user\n",
    "*  \"compliment_note\": number of note compliments received by the user\n",
    "*  \"compliment_plain\": number of plain compliments received by the user\n",
    "*  \"compliment_cool\": number of cool compliments received by the user\n",
    "*  \"compliment_funny\": number of funny compliments received by the user\n",
    "*  \"compliment_writer\": number of writer compliments received by the user\n",
    "*  \"compliment_photos\": number of photo compliments received by the user\n",
    "*  \"type\":\"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the data about Yelp users in an RDD\n",
    "# each RDD element is a Python dictionary parsed from JSON using json.loads()\n",
    "# if your chosen project does not need this data, please comment out the lines below\n",
    "users_rdd = get_rdd_from_url('https://www.andrew.cmu.edu/user/amaurya/docs/95869/yelp_academic_dataset_user.json')\n",
    "print users_rdd.count()\n",
    "print users_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The third dataset we are going to load is information about business checkins reported by users on Yelp. Each checkin's information will be stored as a Python dictionary within an RDD. The dictionary consists of the following fields:\n",
    "\n",
    "*  \"checkin_info\":[\"an array of check ins with the format day-hour:number of check ins from hour to hour+1\"]\n",
    "*  \"business_id\":\"encrypted business id\"\n",
    "*  \"type\":\"checkin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the data about business checkins reported by users on Yelp in an RDD\n",
    "# each RDD element is a Python dictionary parsed from JSON using json.loads()\n",
    "# if your chosen project does not need this data, please comment out the lines below\n",
    "checkins_rdd = get_rdd_from_url('https://www.andrew.cmu.edu/user/amaurya/docs/95869/yelp_academic_dataset_checkin.json')\n",
    "print checkins_rdd.count()\n",
    "print checkins_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The fourth dataset we are going to load is information about business reviews written by users on Yelp. Each review's data will be stored as a Python dictionary within an RDD. The dictionary consists of the following fields:\n",
    "\n",
    "*  \"review_id\":\"encrypted review id\"\n",
    "*  \"user_id\":\"encrypted user id\"\n",
    "*  \"business_id\":\"encrypted business id\"\n",
    "*  \"stars\":star rating rounded to half-stars\n",
    "*  \"date\":\"date formatted like 2009-12-19\"\n",
    "*  \"text\":\"review text\"\n",
    "*  \"useful\":number of useful votes received\n",
    "*  \"funny\":number of funny votes received\n",
    "*  \"cool\": number of cool review votes received\n",
    "*  \"type\": \"review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the data about business reviews written by users on Yelp in an RDD, limited to businesses in Pittsburgh due to DataBricks computational limits\n",
    "# each RDD element is a Python dictionary parsed from JSON using json.loads()\n",
    "# if your chosen project does not need this data, please comment out the lines below\n",
    "reviews_rdd = get_rdd_from_url('https://www.andrew.cmu.edu/user/amaurya/docs/95869/yelp_academic_dataset_review_pittsburgh.json')\n",
    "print reviews_rdd.count()\n",
    "print reviews_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, we will load two lists. The first list consists of male names, and the second list consists of female names. You can use these lists to predict the gender of Yelp users if you plan to do any gender-based analysis of users or their reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper function to load a list of names from a publicly accessible url\n",
    "def get_names_from_url(url):\n",
    "  response = urllib2.urlopen(url)\n",
    "  str_contents = response.read().strip().split('\\n')\n",
    "  result = str_contents[6:]\n",
    "  return result\n",
    "\n",
    "male_names = get_names_from_url('https://www.andrew.cmu.edu/user/amaurya/docs/95869/male.txt')\n",
    "print('First five male names: ', male_names[:5])\n",
    "\n",
    "female_names = get_names_from_url('https://www.andrew.cmu.edu/user/amaurya/docs/95869/female.txt')\n",
    "print('First five female names: ', female_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ** Part 2: Introduction, Motivation, and Problem Definition **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please write your answer here. Add additional IPython code/markup cells as needed. Please the grading rubric at the top of this notebook to understand expectations from this section.\n",
    "\n",
    "Describe your chosen problem and why you think it is interesting from a business perspective. Also mention which of the four datasets you will use for the analysis. What metric(s) will you use to evaluate methods on your chosen task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ** Part 3: Data Understanding and Preparation **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please write your answer here. Add additional IPython code/markup cells as needed. Please the grading rubric at the top of this notebook to understand expectations from this section.\n",
    "\n",
    "Describe your exploratory data analysis in this section. This is really important because it establishes that the datasets you are exploring is capable of answering your chosen project question. Make this section rich with visualization to give the reader a comprehensive understanding of the datasets you have chosen to use.\n",
    "\n",
    "Below, you are provided helper code to install matplotlib's extra toolkit \"mpl_toolkits\" required for drawing maps. Also provided is an example map created using mpl_toolkits. You can refer to Matplotlib Basemap Toolkit documentation [here](https://matplotlib.org/basemap/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sh -e\n",
    "\n",
    "# shell commands to install mpl_toolkits\n",
    "sudo pip install matplotlib\n",
    "cd /databricks\n",
    "mkdir -p mpl_toolkit\n",
    "cd mpl_toolkit\n",
    "\n",
    "wget https://www.andrew.cmu.edu/user/amaurya/docs/95869/basemap-1.0.7.tar.gz\n",
    "tar -xvf basemap-1.0.7.tar.gz\n",
    "\n",
    "cd basemap-1.0.7/geos-3.3.3\n",
    "export GEOS_DIR=/usr/local\n",
    "./configure --prefix=$GEOS_DIR\n",
    "make; make install\n",
    "cd ..\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits\n",
    "mpl_toolkits.__path__.append('/usr/local/lib/python2.7/dist-packages/mpl_toolkits/')\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
    "                gridWidth=1.0):\n",
    "    \"\"\"Template for generating the plot layout.\"\"\"\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = preparePlot(np.arange(0, 100, 20), np.arange(0, 100, 20))\n",
    "m = Basemap(projection='merc',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='coral',lake_color='aqua')\n",
    "m.drawparallels(np.arange(-90.,91.,30.))\n",
    "m.drawmeridians(np.arange(-180.,181.,60.))\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "plt.title(\"Mercator Projection\")\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = preparePlot(np.arange(0, 100, 20), np.arange(0, 100, 20))\n",
    "m = Basemap(width=12000000,height=9000000,projection='lcc', resolution=None,lat_1=45.,lat_2=55,lat_0=50,lon_0=-107.)\n",
    "m.bluemarble()\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ** Part 4: Methodology **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please write your answer here. Add additional IPython code/markup cells as needed. Please the grading rubric at the top of this notebook to understand expectations from this section.\n",
    "\n",
    "In this section, explain what method you have chosen to address the chosen problem. Are you going to be using regression, classification, clustering, topic modeling, collaborative filtering, or a combination of some of these? Describe why this method is suitable for answering your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ** Part 5: Evaluation and Results **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please write your answer here. Add additional IPython code/markup cells as needed. Please the grading rubric at the top of this notebook to understand expectations from this section.\n",
    "\n",
    "In this section, describe all experiemntal parameters such as those used for grid search on hyperparameters. Include results of the chosen methods on your task. How does the metric of interest vary with changes in important method hyperparameters such as regularization, number of iterations, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ** Part 6: Conclusions **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please write your answer here. Add additional IPython code/markup cells as needed. Please the grading rubric at the top of this notebook to understand expectations from this section.\n",
    "\n",
    "This should be a short final section stating whether the methods you explored on Yelp dataset were able to satisfactorily solve the problem you set out to solve. Discuss any business implications of the performance metrics you obtained such as accuracy, RMSE, runtime, etc. Finally, state if you think this implementation is ready for production-deployment or if there are kinks that need to be worked through before it is usable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "project_yelp_dataset",
  "notebookId": 2211594998235697
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
